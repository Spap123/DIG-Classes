{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler,MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_breast_cancer\n",
      "load_diabetes\n",
      "load_digits\n",
      "load_files\n",
      "load_iris\n",
      "load_linnerud\n",
      "load_sample_image\n",
      "load_sample_images\n",
      "load_svmlight_file\n",
      "load_svmlight_files\n",
      "load_wine\n"
     ]
    }
   ],
   "source": [
    "for i in dir(datasets):\n",
    "    if i.startswith('load'):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = datasets.make_regression(n_samples = 40 , n_features = 8, n_informative = 5, n_targets = 1  ,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2766908 , -0.88951443, -0.75373616, -0.07710171,  0.82718325,\n",
       "        -0.24538812, -0.81581028,  0.34115197],\n",
       "       [ 0.25049285, -1.23695071,  0.78182287,  0.52194157,  0.34644821,\n",
       "         0.25988279, -1.32045661,  0.29698467],\n",
       "       [ 1.57921282,  0.64768854, -0.1382643 , -0.23415337,  0.76743473,\n",
       "         0.49671415,  1.52302986, -0.23413696],\n",
       "       [-0.60170661, -1.15099358,  0.11092259, -0.60063869,  1.85227818,\n",
       "        -0.54438272,  0.37569802, -0.29169375],\n",
       "       [-1.51936997, -1.26088395,  0.40498171,  2.1221562 , -0.48423407,\n",
       "         1.76545424,  0.91786195,  1.03246526],\n",
       "       [-1.1913035 ,  0.29307247,  0.2322537 ,  1.86577451,  0.65655361,\n",
       "        -0.68002472, -0.71435142,  0.47383292],\n",
       "       [ 0.74729361,  0.81286212,  0.30729952, -0.82899501,  0.61037027,\n",
       "         0.89959988,  0.62962884, -0.56018104],\n",
       "       [-0.31526924,  0.57089051,  3.85273149,  0.95400176,  0.75896922,\n",
       "         0.51504769,  1.13556564,  0.65139125],\n",
       "       [-3.24126734,  0.44381943, -0.70766947, -0.92693047, -1.02438764,\n",
       "         1.26691115,  0.77463405, -0.05952536],\n",
       "       [-0.2176812 ,  1.2776649 ,  0.11732738,  0.54709738,  1.09877685,\n",
       "        -0.02090159, -0.59157139, -0.20219265],\n",
       "       [ 0.51503527,  1.08305124,  0.56078453, -1.37766937,  0.51378595,\n",
       "         0.35778736,  1.05380205, -0.93782504],\n",
       "       [ 0.68626019, -0.48536355, -0.23681861,  2.31465857, -1.61271587,\n",
       "        -0.77282521,  0.08187414, -1.86726519],\n",
       "       [-1.72491783, -0.46341769,  0.54256004,  0.24196227, -0.56228753,\n",
       "        -0.46947439, -0.46572975, -1.91328024],\n",
       "       [-0.44651495,  0.47323762,  0.71400049, -0.84679372,  0.85639879,\n",
       "        -0.22346279, -0.07282891, -1.51484722],\n",
       "       [ 1.44127329,  1.6324113 , -1.24778318, -0.44004449, -1.43586215,\n",
       "        -0.25256815, -1.43014138,  0.13074058],\n",
       "       [-1.10633497,  0.33126343, -0.30921238, -0.47917424, -1.19620662,\n",
       "        -0.83921752,  0.97554513, -0.18565898],\n",
       "       [-0.34271452,  0.00511346,  0.26105527, -1.41537074, -0.80227727,\n",
       "         0.29612028, -0.23458713, -0.42064532],\n",
       "       [ 0.06980208, -0.98150865,  0.01023306,  0.1990597 , -0.3853136 ,\n",
       "         1.16316375,  0.46210347, -0.60021688],\n",
       "       [ 1.03099952,  0.32408397, -1.76304016, -0.676922  ,  0.93128012,\n",
       "         0.34361829, -0.38508228,  0.61167629],\n",
       "       [-0.46063877, -0.11564828,  0.17136828, -1.47852199,  1.05712223,\n",
       "         0.73846658, -0.3011037 , -0.71984421],\n",
       "       [-0.91942423, -1.55066343, -0.50347565, -1.06230371,  1.54993441,\n",
       "         0.09965137,  0.06856297,  0.47359243],\n",
       "       [ 0.32416635,  1.30547881,  0.81350964,  0.68195297, -0.13014305,\n",
       "         0.82541635,  0.02100384, -0.31026676],\n",
       "       [ 0.09176078, -2.6197451 ,  1.56464366,  0.08704707, -1.98756891,\n",
       "        -0.03582604,  0.8219025 , -0.29900735],\n",
       "       [ 0.36139561, -0.07201012,  1.35624003,  0.36163603,  1.53803657,\n",
       "         0.81252582,  1.0035329 , -0.64511975],\n",
       "       [-0.39210815,  0.09707755,  0.51326743, -0.70205309, -1.46351495,\n",
       "        -0.5297602 ,  0.96864499, -0.32766215],\n",
       "       [ 1.14282281, -0.19236096,  2.46324211, -0.03471177,  0.75193303,\n",
       "         0.06023021,  0.30154734, -1.16867804],\n",
       "       [-1.60748323,  0.81351722, -0.32206152,  0.22745993,  0.18463386,\n",
       "        -0.78325329, -1.23086432,  1.30714275],\n",
       "       [-0.66178646,  2.14394409, -0.65160035, -2.02514259,  0.85243333,\n",
       "         0.04557184,  0.63391902,  0.18645431],\n",
       "       [ 0.91540212,  1.47789404,  0.35711257, -0.8084936 ,  0.32875111,\n",
       "        -0.21967189, -0.51827022, -0.50175704],\n",
       "       [-0.73036663,  0.06428002,  1.0889506 , -0.71530371,  0.21645859,\n",
       "        -0.47193187, -1.07774478,  0.67959775],\n",
       "       [ 0.35701549, -0.20812225, -0.62269952, -0.58936476, -0.6929096 ,\n",
       "         0.28099187, -0.49300093,  0.8496021 ],\n",
       "       [ 0.0675282 , -0.90802408,  0.31424733,  1.46564877, -1.42474819,\n",
       "        -1.01283112, -1.4123037 , -0.2257763 ],\n",
       "       [-1.32818605,  0.82254491, -1.05771093,  0.2088636 ,  0.19686124,\n",
       "        -0.01349722, -1.22084365, -1.95967012],\n",
       "       [-0.47494531,  0.50498728, -0.11473644, -1.20029641, -0.65332923,\n",
       "        -0.79252074,  0.86575519, -0.33450124],\n",
       "       [-1.91877122,  1.8861859 ,  0.40405086,  0.25755039, -0.02651388,\n",
       "        -0.16128571,  0.17457781, -0.07444592],\n",
       "       [-0.99053633,  1.40279431, -0.90938745,  0.58685709, -0.56629773,\n",
       "         0.79103195, -1.40185106,  2.19045563],\n",
       "       [-1.0708925 , -0.26465683,  1.45353408,  0.62566735,  0.48247242,\n",
       "         0.01300189,  2.72016917, -0.85715756],\n",
       "       [-0.1517851 ,  1.58601682,  0.66213067,  2.13303337,  0.58831721,\n",
       "         0.11351735, -1.2378155 , -1.9520878 ],\n",
       "       [ 0.82206016,  1.15859558,  0.7870846 ,  0.96337613,  1.89679298,\n",
       "        -0.97468167, -0.82068232,  0.41278093],\n",
       "       [ 0.05820872,  0.17318093, -1.24573878, -0.88385744, -1.1429703 ,\n",
       "         0.21409374,  0.38531738,  0.15372511]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-161.59704093,  -52.52921566,  141.64673825, -118.8761106 ,\n",
       "        214.7662009 ,  -10.13617066,  158.42637621,  384.85830094,\n",
       "        115.45471128,   74.98142932,  141.46277072,  -46.17257692,\n",
       "        -56.58742422,   21.50699168,  -69.45673154,  -46.87959085,\n",
       "         -8.57775891,   75.70207916,  -85.07489561,   15.86426079,\n",
       "       -145.44817079,  228.53690539,  -39.79813427,  206.06790093,\n",
       "          8.06053441,  147.32804978,  -90.05198905,   71.47767722,\n",
       "         46.02736736,  -47.66063379,  -61.5358159 , -155.99238393,\n",
       "        -58.58884075,  -46.3796142 ,  142.39463485,   66.02400372,\n",
       "        208.19512548,  156.00412033,   17.12895196,  -48.77752852])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-161.597041</th>\n",
       "      <td>0.276691</td>\n",
       "      <td>-0.889514</td>\n",
       "      <td>-0.753736</td>\n",
       "      <td>-0.077102</td>\n",
       "      <td>0.827183</td>\n",
       "      <td>-0.245388</td>\n",
       "      <td>-0.815810</td>\n",
       "      <td>0.341152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-52.529216</th>\n",
       "      <td>0.250493</td>\n",
       "      <td>-1.236951</td>\n",
       "      <td>0.781823</td>\n",
       "      <td>0.521942</td>\n",
       "      <td>0.346448</td>\n",
       "      <td>0.259883</td>\n",
       "      <td>-1.320457</td>\n",
       "      <td>0.296985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141.646738</th>\n",
       "      <td>1.579213</td>\n",
       "      <td>0.647689</td>\n",
       "      <td>-0.138264</td>\n",
       "      <td>-0.234153</td>\n",
       "      <td>0.767435</td>\n",
       "      <td>0.496714</td>\n",
       "      <td>1.523030</td>\n",
       "      <td>-0.234137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-118.876111</th>\n",
       "      <td>-0.601707</td>\n",
       "      <td>-1.150994</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>-0.600639</td>\n",
       "      <td>1.852278</td>\n",
       "      <td>-0.544383</td>\n",
       "      <td>0.375698</td>\n",
       "      <td>-0.291694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214.766201</th>\n",
       "      <td>-1.519370</td>\n",
       "      <td>-1.260884</td>\n",
       "      <td>0.404982</td>\n",
       "      <td>2.122156</td>\n",
       "      <td>-0.484234</td>\n",
       "      <td>1.765454</td>\n",
       "      <td>0.917862</td>\n",
       "      <td>1.032465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-10.136171</th>\n",
       "      <td>-1.191303</td>\n",
       "      <td>0.293072</td>\n",
       "      <td>0.232254</td>\n",
       "      <td>1.865775</td>\n",
       "      <td>0.656554</td>\n",
       "      <td>-0.680025</td>\n",
       "      <td>-0.714351</td>\n",
       "      <td>0.473833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158.426376</th>\n",
       "      <td>0.747294</td>\n",
       "      <td>0.812862</td>\n",
       "      <td>0.307300</td>\n",
       "      <td>-0.828995</td>\n",
       "      <td>0.610370</td>\n",
       "      <td>0.899600</td>\n",
       "      <td>0.629629</td>\n",
       "      <td>-0.560181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384.858301</th>\n",
       "      <td>-0.315269</td>\n",
       "      <td>0.570891</td>\n",
       "      <td>3.852731</td>\n",
       "      <td>0.954002</td>\n",
       "      <td>0.758969</td>\n",
       "      <td>0.515048</td>\n",
       "      <td>1.135566</td>\n",
       "      <td>0.651391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115.454711</th>\n",
       "      <td>-3.241267</td>\n",
       "      <td>0.443819</td>\n",
       "      <td>-0.707669</td>\n",
       "      <td>-0.926930</td>\n",
       "      <td>-1.024388</td>\n",
       "      <td>1.266911</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.059525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74.981429</th>\n",
       "      <td>-0.217681</td>\n",
       "      <td>1.277665</td>\n",
       "      <td>0.117327</td>\n",
       "      <td>0.547097</td>\n",
       "      <td>1.098777</td>\n",
       "      <td>-0.020902</td>\n",
       "      <td>-0.591571</td>\n",
       "      <td>-0.202193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141.462771</th>\n",
       "      <td>0.515035</td>\n",
       "      <td>1.083051</td>\n",
       "      <td>0.560785</td>\n",
       "      <td>-1.377669</td>\n",
       "      <td>0.513786</td>\n",
       "      <td>0.357787</td>\n",
       "      <td>1.053802</td>\n",
       "      <td>-0.937825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-46.172577</th>\n",
       "      <td>0.686260</td>\n",
       "      <td>-0.485364</td>\n",
       "      <td>-0.236819</td>\n",
       "      <td>2.314659</td>\n",
       "      <td>-1.612716</td>\n",
       "      <td>-0.772825</td>\n",
       "      <td>0.081874</td>\n",
       "      <td>-1.867265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-56.587424</th>\n",
       "      <td>-1.724918</td>\n",
       "      <td>-0.463418</td>\n",
       "      <td>0.542560</td>\n",
       "      <td>0.241962</td>\n",
       "      <td>-0.562288</td>\n",
       "      <td>-0.469474</td>\n",
       "      <td>-0.465730</td>\n",
       "      <td>-1.913280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.506992</th>\n",
       "      <td>-0.446515</td>\n",
       "      <td>0.473238</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>-0.846794</td>\n",
       "      <td>0.856399</td>\n",
       "      <td>-0.223463</td>\n",
       "      <td>-0.072829</td>\n",
       "      <td>-1.514847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-69.456732</th>\n",
       "      <td>1.441273</td>\n",
       "      <td>1.632411</td>\n",
       "      <td>-1.247783</td>\n",
       "      <td>-0.440044</td>\n",
       "      <td>-1.435862</td>\n",
       "      <td>-0.252568</td>\n",
       "      <td>-1.430141</td>\n",
       "      <td>0.130741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-46.879591</th>\n",
       "      <td>-1.106335</td>\n",
       "      <td>0.331263</td>\n",
       "      <td>-0.309212</td>\n",
       "      <td>-0.479174</td>\n",
       "      <td>-1.196207</td>\n",
       "      <td>-0.839218</td>\n",
       "      <td>0.975545</td>\n",
       "      <td>-0.185659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8.577759</th>\n",
       "      <td>-0.342715</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.261055</td>\n",
       "      <td>-1.415371</td>\n",
       "      <td>-0.802277</td>\n",
       "      <td>0.296120</td>\n",
       "      <td>-0.234587</td>\n",
       "      <td>-0.420645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75.702079</th>\n",
       "      <td>0.069802</td>\n",
       "      <td>-0.981509</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.199060</td>\n",
       "      <td>-0.385314</td>\n",
       "      <td>1.163164</td>\n",
       "      <td>0.462103</td>\n",
       "      <td>-0.600217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-85.074896</th>\n",
       "      <td>1.031000</td>\n",
       "      <td>0.324084</td>\n",
       "      <td>-1.763040</td>\n",
       "      <td>-0.676922</td>\n",
       "      <td>0.931280</td>\n",
       "      <td>0.343618</td>\n",
       "      <td>-0.385082</td>\n",
       "      <td>0.611676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.864261</th>\n",
       "      <td>-0.460639</td>\n",
       "      <td>-0.115648</td>\n",
       "      <td>0.171368</td>\n",
       "      <td>-1.478522</td>\n",
       "      <td>1.057122</td>\n",
       "      <td>0.738467</td>\n",
       "      <td>-0.301104</td>\n",
       "      <td>-0.719844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-145.448171</th>\n",
       "      <td>-0.919424</td>\n",
       "      <td>-1.550663</td>\n",
       "      <td>-0.503476</td>\n",
       "      <td>-1.062304</td>\n",
       "      <td>1.549934</td>\n",
       "      <td>0.099651</td>\n",
       "      <td>0.068563</td>\n",
       "      <td>0.473592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228.536905</th>\n",
       "      <td>0.324166</td>\n",
       "      <td>1.305479</td>\n",
       "      <td>0.813510</td>\n",
       "      <td>0.681953</td>\n",
       "      <td>-0.130143</td>\n",
       "      <td>0.825416</td>\n",
       "      <td>0.021004</td>\n",
       "      <td>-0.310267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-39.798134</th>\n",
       "      <td>0.091761</td>\n",
       "      <td>-2.619745</td>\n",
       "      <td>1.564644</td>\n",
       "      <td>0.087047</td>\n",
       "      <td>-1.987569</td>\n",
       "      <td>-0.035826</td>\n",
       "      <td>0.821903</td>\n",
       "      <td>-0.299007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206.067901</th>\n",
       "      <td>0.361396</td>\n",
       "      <td>-0.072010</td>\n",
       "      <td>1.356240</td>\n",
       "      <td>0.361636</td>\n",
       "      <td>1.538037</td>\n",
       "      <td>0.812526</td>\n",
       "      <td>1.003533</td>\n",
       "      <td>-0.645120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.060534</th>\n",
       "      <td>-0.392108</td>\n",
       "      <td>0.097078</td>\n",
       "      <td>0.513267</td>\n",
       "      <td>-0.702053</td>\n",
       "      <td>-1.463515</td>\n",
       "      <td>-0.529760</td>\n",
       "      <td>0.968645</td>\n",
       "      <td>-0.327662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147.328050</th>\n",
       "      <td>1.142823</td>\n",
       "      <td>-0.192361</td>\n",
       "      <td>2.463242</td>\n",
       "      <td>-0.034712</td>\n",
       "      <td>0.751933</td>\n",
       "      <td>0.060230</td>\n",
       "      <td>0.301547</td>\n",
       "      <td>-1.168678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-90.051989</th>\n",
       "      <td>-1.607483</td>\n",
       "      <td>0.813517</td>\n",
       "      <td>-0.322062</td>\n",
       "      <td>0.227460</td>\n",
       "      <td>0.184634</td>\n",
       "      <td>-0.783253</td>\n",
       "      <td>-1.230864</td>\n",
       "      <td>1.307143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.477677</th>\n",
       "      <td>-0.661786</td>\n",
       "      <td>2.143944</td>\n",
       "      <td>-0.651600</td>\n",
       "      <td>-2.025143</td>\n",
       "      <td>0.852433</td>\n",
       "      <td>0.045572</td>\n",
       "      <td>0.633919</td>\n",
       "      <td>0.186454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.027367</th>\n",
       "      <td>0.915402</td>\n",
       "      <td>1.477894</td>\n",
       "      <td>0.357113</td>\n",
       "      <td>-0.808494</td>\n",
       "      <td>0.328751</td>\n",
       "      <td>-0.219672</td>\n",
       "      <td>-0.518270</td>\n",
       "      <td>-0.501757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-47.660634</th>\n",
       "      <td>-0.730367</td>\n",
       "      <td>0.064280</td>\n",
       "      <td>1.088951</td>\n",
       "      <td>-0.715304</td>\n",
       "      <td>0.216459</td>\n",
       "      <td>-0.471932</td>\n",
       "      <td>-1.077745</td>\n",
       "      <td>0.679598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-61.535816</th>\n",
       "      <td>0.357015</td>\n",
       "      <td>-0.208122</td>\n",
       "      <td>-0.622700</td>\n",
       "      <td>-0.589365</td>\n",
       "      <td>-0.692910</td>\n",
       "      <td>0.280992</td>\n",
       "      <td>-0.493001</td>\n",
       "      <td>0.849602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-155.992384</th>\n",
       "      <td>0.067528</td>\n",
       "      <td>-0.908024</td>\n",
       "      <td>0.314247</td>\n",
       "      <td>1.465649</td>\n",
       "      <td>-1.424748</td>\n",
       "      <td>-1.012831</td>\n",
       "      <td>-1.412304</td>\n",
       "      <td>-0.225776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-58.588841</th>\n",
       "      <td>-1.328186</td>\n",
       "      <td>0.822545</td>\n",
       "      <td>-1.057711</td>\n",
       "      <td>0.208864</td>\n",
       "      <td>0.196861</td>\n",
       "      <td>-0.013497</td>\n",
       "      <td>-1.220844</td>\n",
       "      <td>-1.959670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-46.379614</th>\n",
       "      <td>-0.474945</td>\n",
       "      <td>0.504987</td>\n",
       "      <td>-0.114736</td>\n",
       "      <td>-1.200296</td>\n",
       "      <td>-0.653329</td>\n",
       "      <td>-0.792521</td>\n",
       "      <td>0.865755</td>\n",
       "      <td>-0.334501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142.394635</th>\n",
       "      <td>-1.918771</td>\n",
       "      <td>1.886186</td>\n",
       "      <td>0.404051</td>\n",
       "      <td>0.257550</td>\n",
       "      <td>-0.026514</td>\n",
       "      <td>-0.161286</td>\n",
       "      <td>0.174578</td>\n",
       "      <td>-0.074446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.024004</th>\n",
       "      <td>-0.990536</td>\n",
       "      <td>1.402794</td>\n",
       "      <td>-0.909387</td>\n",
       "      <td>0.586857</td>\n",
       "      <td>-0.566298</td>\n",
       "      <td>0.791032</td>\n",
       "      <td>-1.401851</td>\n",
       "      <td>2.190456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208.195125</th>\n",
       "      <td>-1.070892</td>\n",
       "      <td>-0.264657</td>\n",
       "      <td>1.453534</td>\n",
       "      <td>0.625667</td>\n",
       "      <td>0.482472</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>2.720169</td>\n",
       "      <td>-0.857158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156.004120</th>\n",
       "      <td>-0.151785</td>\n",
       "      <td>1.586017</td>\n",
       "      <td>0.662131</td>\n",
       "      <td>2.133033</td>\n",
       "      <td>0.588317</td>\n",
       "      <td>0.113517</td>\n",
       "      <td>-1.237815</td>\n",
       "      <td>-1.952088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.128952</th>\n",
       "      <td>0.822060</td>\n",
       "      <td>1.158596</td>\n",
       "      <td>0.787085</td>\n",
       "      <td>0.963376</td>\n",
       "      <td>1.896793</td>\n",
       "      <td>-0.974682</td>\n",
       "      <td>-0.820682</td>\n",
       "      <td>0.412781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-48.777529</th>\n",
       "      <td>0.058209</td>\n",
       "      <td>0.173181</td>\n",
       "      <td>-1.245739</td>\n",
       "      <td>-0.883857</td>\n",
       "      <td>-1.142970</td>\n",
       "      <td>0.214094</td>\n",
       "      <td>0.385317</td>\n",
       "      <td>0.153725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5  \\\n",
       "-161.597041  0.276691 -0.889514 -0.753736 -0.077102  0.827183 -0.245388   \n",
       "-52.529216   0.250493 -1.236951  0.781823  0.521942  0.346448  0.259883   \n",
       " 141.646738  1.579213  0.647689 -0.138264 -0.234153  0.767435  0.496714   \n",
       "-118.876111 -0.601707 -1.150994  0.110923 -0.600639  1.852278 -0.544383   \n",
       " 214.766201 -1.519370 -1.260884  0.404982  2.122156 -0.484234  1.765454   \n",
       "-10.136171  -1.191303  0.293072  0.232254  1.865775  0.656554 -0.680025   \n",
       " 158.426376  0.747294  0.812862  0.307300 -0.828995  0.610370  0.899600   \n",
       " 384.858301 -0.315269  0.570891  3.852731  0.954002  0.758969  0.515048   \n",
       " 115.454711 -3.241267  0.443819 -0.707669 -0.926930 -1.024388  1.266911   \n",
       " 74.981429  -0.217681  1.277665  0.117327  0.547097  1.098777 -0.020902   \n",
       " 141.462771  0.515035  1.083051  0.560785 -1.377669  0.513786  0.357787   \n",
       "-46.172577   0.686260 -0.485364 -0.236819  2.314659 -1.612716 -0.772825   \n",
       "-56.587424  -1.724918 -0.463418  0.542560  0.241962 -0.562288 -0.469474   \n",
       " 21.506992  -0.446515  0.473238  0.714000 -0.846794  0.856399 -0.223463   \n",
       "-69.456732   1.441273  1.632411 -1.247783 -0.440044 -1.435862 -0.252568   \n",
       "-46.879591  -1.106335  0.331263 -0.309212 -0.479174 -1.196207 -0.839218   \n",
       "-8.577759   -0.342715  0.005113  0.261055 -1.415371 -0.802277  0.296120   \n",
       " 75.702079   0.069802 -0.981509  0.010233  0.199060 -0.385314  1.163164   \n",
       "-85.074896   1.031000  0.324084 -1.763040 -0.676922  0.931280  0.343618   \n",
       " 15.864261  -0.460639 -0.115648  0.171368 -1.478522  1.057122  0.738467   \n",
       "-145.448171 -0.919424 -1.550663 -0.503476 -1.062304  1.549934  0.099651   \n",
       " 228.536905  0.324166  1.305479  0.813510  0.681953 -0.130143  0.825416   \n",
       "-39.798134   0.091761 -2.619745  1.564644  0.087047 -1.987569 -0.035826   \n",
       " 206.067901  0.361396 -0.072010  1.356240  0.361636  1.538037  0.812526   \n",
       " 8.060534   -0.392108  0.097078  0.513267 -0.702053 -1.463515 -0.529760   \n",
       " 147.328050  1.142823 -0.192361  2.463242 -0.034712  0.751933  0.060230   \n",
       "-90.051989  -1.607483  0.813517 -0.322062  0.227460  0.184634 -0.783253   \n",
       " 71.477677  -0.661786  2.143944 -0.651600 -2.025143  0.852433  0.045572   \n",
       " 46.027367   0.915402  1.477894  0.357113 -0.808494  0.328751 -0.219672   \n",
       "-47.660634  -0.730367  0.064280  1.088951 -0.715304  0.216459 -0.471932   \n",
       "-61.535816   0.357015 -0.208122 -0.622700 -0.589365 -0.692910  0.280992   \n",
       "-155.992384  0.067528 -0.908024  0.314247  1.465649 -1.424748 -1.012831   \n",
       "-58.588841  -1.328186  0.822545 -1.057711  0.208864  0.196861 -0.013497   \n",
       "-46.379614  -0.474945  0.504987 -0.114736 -1.200296 -0.653329 -0.792521   \n",
       " 142.394635 -1.918771  1.886186  0.404051  0.257550 -0.026514 -0.161286   \n",
       " 66.024004  -0.990536  1.402794 -0.909387  0.586857 -0.566298  0.791032   \n",
       " 208.195125 -1.070892 -0.264657  1.453534  0.625667  0.482472  0.013002   \n",
       " 156.004120 -0.151785  1.586017  0.662131  2.133033  0.588317  0.113517   \n",
       " 17.128952   0.822060  1.158596  0.787085  0.963376  1.896793 -0.974682   \n",
       "-48.777529   0.058209  0.173181 -1.245739 -0.883857 -1.142970  0.214094   \n",
       "\n",
       "                    6         7  \n",
       "-161.597041 -0.815810  0.341152  \n",
       "-52.529216  -1.320457  0.296985  \n",
       " 141.646738  1.523030 -0.234137  \n",
       "-118.876111  0.375698 -0.291694  \n",
       " 214.766201  0.917862  1.032465  \n",
       "-10.136171  -0.714351  0.473833  \n",
       " 158.426376  0.629629 -0.560181  \n",
       " 384.858301  1.135566  0.651391  \n",
       " 115.454711  0.774634 -0.059525  \n",
       " 74.981429  -0.591571 -0.202193  \n",
       " 141.462771  1.053802 -0.937825  \n",
       "-46.172577   0.081874 -1.867265  \n",
       "-56.587424  -0.465730 -1.913280  \n",
       " 21.506992  -0.072829 -1.514847  \n",
       "-69.456732  -1.430141  0.130741  \n",
       "-46.879591   0.975545 -0.185659  \n",
       "-8.577759   -0.234587 -0.420645  \n",
       " 75.702079   0.462103 -0.600217  \n",
       "-85.074896  -0.385082  0.611676  \n",
       " 15.864261  -0.301104 -0.719844  \n",
       "-145.448171  0.068563  0.473592  \n",
       " 228.536905  0.021004 -0.310267  \n",
       "-39.798134   0.821903 -0.299007  \n",
       " 206.067901  1.003533 -0.645120  \n",
       " 8.060534    0.968645 -0.327662  \n",
       " 147.328050  0.301547 -1.168678  \n",
       "-90.051989  -1.230864  1.307143  \n",
       " 71.477677   0.633919  0.186454  \n",
       " 46.027367  -0.518270 -0.501757  \n",
       "-47.660634  -1.077745  0.679598  \n",
       "-61.535816  -0.493001  0.849602  \n",
       "-155.992384 -1.412304 -0.225776  \n",
       "-58.588841  -1.220844 -1.959670  \n",
       "-46.379614   0.865755 -0.334501  \n",
       " 142.394635  0.174578 -0.074446  \n",
       " 66.024004  -1.401851  2.190456  \n",
       " 208.195125  2.720169 -0.857158  \n",
       " 156.004120 -1.237815 -1.952088  \n",
       " 17.128952  -0.820682  0.412781  \n",
       "-48.777529   0.385317  0.153725  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain , xtest , ytrain, ytest = tts(x,y,test_size = 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = lr.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.86426079,  -8.57775891, -46.87959085, -90.05198905,\n",
       "       214.7662009 , -56.58742422, 156.00412033,  71.47767722])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.86426079,  -8.57775891, -46.87959085, -90.05198905,\n",
       "       214.7662009 , -56.58742422, 156.00412033,  71.47767722])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge,Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmodel = Lasso()\n",
    "lmodel.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmred = lmodel.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.86426079,  -8.57775891, -46.87959085, -90.05198905,\n",
       "       214.7662009 , -56.58742422, 156.00412033,  71.47767722])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.35500077,  -6.13976012, -44.32492356, -87.46507057,\n",
       "       206.3285404 , -54.49039455, 151.26550097,  72.93294886])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmodel = Ridge()\n",
    "rmodel.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmpred = rmodel.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.86426079,  -8.57775891, -46.87959085, -90.05198905,\n",
       "       214.7662009 , -56.58742422, 156.00412033,  71.47767722])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14.14433454,  -8.06164763, -38.46199987, -82.77752028,\n",
       "       199.25034665, -52.73771196, 147.44233871,  74.13310746])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data score in linear model is 1.0\n",
      "testing data score in linear model is 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'training data score in linear model is {lr.score(xtrain,ytrain)}')\n",
    "print(f'testing data score in linear model is {lr.score(xtest,ytest)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data score in Ridge model is 0.9981247492949864\n",
      "testing data score in Ridge model is 0.9942999327265917\n"
     ]
    }
   ],
   "source": [
    "print(f'training data score in Ridge model is {rmodel.score(xtrain,ytrain)}')\n",
    "print(f'testing data score in Ridge model is {rmodel.score(xtest,ytest)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data score in Lasso model is 0.9995570968197268\n",
      "testing data score in Lasso model is 0.9985033232115915\n"
     ]
    }
   ],
   "source": [
    "print(f'training data score in Lasso model is {lmodel.score(xtrain,ytrain)}')\n",
    "print(f'testing data score in Lasso model is {lmodel.score(xtest,ytest)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the ridge model score is 0.9999993030818627 while the alpha value is 0.01 and the error arrya is [-0.02235648  0.00381425  0.09505991  0.0805668  -0.17010719  0.03905492\n",
      " -0.09513714  0.03230729] \n",
      " the ridge model score is 0.9999972183308994 while the alpha value is 0.02 and the error arrya is [-0.04459173  0.007662    0.1898723   0.16095676 -0.33988224  0.07810288\n",
      " -0.19005802  0.06448296] \n",
      " the ridge model score is 0.9999937547058368 while the alpha value is 0.03 and the error arrya is [-0.06670633  0.01154301  0.2844381   0.24117052 -0.50932617  0.11714372\n",
      " -0.28476346  0.09652754] \n",
      " the ridge model score is 0.9999889211038681 while the alpha value is 0.04 and the error arrya is [-0.08870089  0.01545706  0.37875828  0.32120871 -0.67843999  0.15617728\n",
      " -0.37925429  0.12844156] \n",
      " the ridge model score is 0.9999827263611393 while the alpha value is 0.05 and the error arrya is [-0.11057598  0.01940394  0.47283376  0.40107199 -0.84722472  0.19520339\n",
      " -0.47353131  0.16022553] \n",
      " the ridge model score is 0.9999751792532335 while the alpha value is 0.06 and the error arrya is [-0.13233219  0.02338343  0.56666548  0.48076098 -1.01568136  0.23422192\n",
      " -0.56759534  0.19187999] \n",
      " the ridge model score is 0.9999662884956497 while the alpha value is 0.07 and the error arrya is [-0.15397011  0.0273953   0.66025439  0.56027632 -1.1838109   0.27323269\n",
      " -0.6614472   0.22340544] \n",
      " the ridge model score is 0.9999560627442767 while the alpha value is 0.08 and the error arrya is [-0.17549031  0.03143934  0.75360139  0.63961865 -1.35161436  0.31223556\n",
      " -0.75508768  0.25480241] \n",
      " the ridge model score is 0.9997578871948546 while the alpha value is 0.19 and the error arrya is [-0.40460531  0.07798671  1.76471392  1.50114191 -3.17621125  0.74070286\n",
      " -1.77140811  0.59183401] \n"
     ]
    }
   ],
   "source": [
    "alpha_lst = [0.01 , 0.02 ,0.03 , 0.04 , 0.05 , 0.06 , 0.07 ,0.08 , 0.19]\n",
    "for i in alpha_lst:\n",
    "    r1model = Ridge(alpha = i)\n",
    "    ridge_model = r1model.fit(xtrain,ytrain)\n",
    "    r1pred = r1model.predict(xtest)\n",
    "    print(f' the ridge model score is {r1model.score(xtest,ytest)} while the alpha value is {i} and the error arrya is {r1pred-ypred} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the lasso model score is 0.9999998552749229 while the alpha value is 0.01 and the error arrya is [ 0.01760533  0.02623423  0.02158051  0.02458498 -0.08325373  0.02111812\n",
      " -0.04624754  0.01300549] \n",
      " the lasso model score is 0.9999994099646449 while the alpha value is 0.02 and the error arrya is [ 0.03192998  0.05020373  0.04794385  0.05071444 -0.16779978  0.04205742\n",
      " -0.09384509  0.02784135] \n",
      " the lasso model score is 0.9999986648203077 while the alpha value is 0.03 and the error arrya is [ 0.0465798   0.07440335  0.0738589   0.07670119 -0.25226124  0.06301161\n",
      " -0.14133006  0.04253129] \n",
      " the lasso model score is 0.9999976196953352 while the alpha value is 0.04 and the error arrya is [ 0.0612957   0.09865132  0.0996871   0.10266125 -0.33671591  0.08397009\n",
      " -0.18879631  0.05719561] \n",
      " the lasso model score is 0.9999963096277499 while the alpha value is 0.05 and the error arrya is [ 0.07956043  0.12532922  0.12025341  0.12691456 -0.41962088  0.10513018\n",
      " -0.23472904  0.06976007] \n",
      " the lasso model score is 0.9999946714365475 while the alpha value is 0.06 and the error arrya is [ 0.09418683  0.14951018  0.14619493  0.15290849 -0.50407456  0.12608184\n",
      " -0.28221659  0.08445463] \n",
      " the lasso model score is 0.9999927333069151 while the alpha value is 0.07 and the error arrya is [ 0.10889594  0.17375325  0.17203244  0.17887145 -0.58853054  0.14703975\n",
      " -0.32968502  0.09912228] \n",
      " the lasso model score is 0.9999904951199454 while the alpha value is 0.08 and the error arrya is [ 0.1236109   0.19800057  0.19786204  0.20483196 -0.67298563  0.16799817\n",
      " -0.37715168  0.11378717] \n",
      " the lasso model score is 0.9999460964807394 while the alpha value is 0.19 and the error arrya is [ 0.28623796  0.46524861  0.48086938  0.49003753 -1.60168958  0.39859183\n",
      " -0.89897129  0.27465414] \n"
     ]
    }
   ],
   "source": [
    "alpha_lst = [0.01 , 0.02 ,0.03 , 0.04 , 0.05 , 0.06 , 0.07 ,0.08 , 0.19]\n",
    "for i in alpha_lst:\n",
    "    l1model = Lasso(alpha = i)\n",
    "    lasso_model = l1model.fit(xtrain,ytrain)\n",
    "    l1pred = l1model.predict(xtest)\n",
    "    print(f' the lasso model score is {l1model.score(xtest,ytest)} while the alpha value is {i} and the error arrya is {l1pred-ypred} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
